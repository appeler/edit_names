{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a46d456",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece8afa",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c04226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import Levenshtein as lv\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer                                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True when you want to regenerate the Levenshtein Distance\n",
    "#  otherwise will load csv file\n",
    "REGEN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91326fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walker</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>palmer</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mc cleod</td>\n",
       "      <td>nh_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scarborough</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walker</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653888</th>\n",
       "      <td>philpott</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653889</th>\n",
       "      <td>walters</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653890</th>\n",
       "      <td>sawyer</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653891</th>\n",
       "      <td>thomas</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653893</th>\n",
       "      <td>bruner</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12989098 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name_last      race\n",
       "0              walker  nh_white\n",
       "1              palmer  nh_white\n",
       "2            mc cleod  nh_black\n",
       "3         scarborough  nh_white\n",
       "4              walker  nh_white\n",
       "...               ...       ...\n",
       "13653888     philpott  nh_white\n",
       "13653889      walters  nh_white\n",
       "13653890       sawyer  nh_white\n",
       "13653891       thomas  nh_white\n",
       "13653893       bruner  nh_white\n",
       "\n",
       "[12989098 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Florida voter file\n",
    "df = pd.read_csv('../dataverse_files/fl_reg_name_race.csv.gz')\n",
    "df.dropna(subset=['name_last'], inplace=True)\n",
    "\n",
    "sdf = df[df.race.isin(['multi_racial', 'native_indian', 'other', 'unknown']) == False]\n",
    "del df\n",
    "\n",
    "# Setting consistent case for names\n",
    "sdf['name_last'] = sdf.name_last.str.lower()\n",
    "\n",
    "# Remove unrequired first name\n",
    "sdf.drop('name_first', axis=1, inplace=True)\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38523827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nh_white    8714118\n",
       "hispanic    2174408\n",
       "nh_black    1847266\n",
       "asian        253306\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the different races filtered\n",
    "sdf.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de025d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the count of each name & race combination\n",
    "gdf = sdf.groupby(['name_last','race'], as_index=False)['race'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f243b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pivot table so that each name has a count of the # of races with that last name\n",
    "gdf = gdf.pivot_table(values='count', columns='race',index='name_last')\n",
    "\n",
    "# Converting NaN to zeros since that means there is no one that identifies with that race with that last name\n",
    "gdf = gdf.fillna(0)\n",
    "\n",
    "# Getting the totals of each last name\n",
    "gdf['total_n'] = gdf.sum(axis=1)\n",
    "gdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0f7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fleurime michel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franklin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grant cliatt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hassan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>king</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>williams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0kharitonenko</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1amirthanayagam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77348 dancing rochanavibhata</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a de feria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a de fernandez</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a f r stephenson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a felix</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a ghaffar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "race                     name_last  asian  hispanic  nh_black  nh_white  \\\n",
       "0                  fleurime michel    0.0       0.0       1.0       0.0   \n",
       "1                         franklin    0.0       0.0       1.0       0.0   \n",
       "2                     grant cliatt    0.0       0.0       1.0       0.0   \n",
       "3                           hassan    1.0       0.0       0.0       0.0   \n",
       "4                             king    0.0       1.0       0.0       0.0   \n",
       "5                         williams    0.0       0.0       0.0       1.0   \n",
       "6                    0kharitonenko    0.0       0.0       0.0       1.0   \n",
       "7                  1amirthanayagam    1.0       0.0       0.0       0.0   \n",
       "8                               4r    0.0       0.0       0.0       1.0   \n",
       "9     77348 dancing rochanavibhata    1.0       0.0       0.0       0.0   \n",
       "10                      a de feria    0.0       1.0       0.0       0.0   \n",
       "11                  a de fernandez    0.0       1.0       0.0       0.0   \n",
       "12                a f r stephenson    0.0       0.0       0.0       1.0   \n",
       "13                         a felix    0.0       1.0       0.0       0.0   \n",
       "14                       a ghaffar    0.0       0.0       0.0       1.0   \n",
       "\n",
       "race  total_n  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         1.0  \n",
       "6         1.0  \n",
       "7         1.0  \n",
       "8         1.0  \n",
       "9         1.0  \n",
       "10        1.0  \n",
       "11        1.0  \n",
       "12        1.0  \n",
       "13        1.0  \n",
       "14        1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63880fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian', 'hispanic', 'nh_black', 'nh_white']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = sorted(sdf.race.unique().tolist())\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee82c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prop(row):\n",
    "    total = row['total_n']\n",
    "    values = [(i/total) for i in row]\n",
    "    return pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cb18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of people with a particular last name\n",
    "#  that identify with one of the 4 races\n",
    "temp = races.copy()\n",
    "temp.append('total_n')\n",
    "\n",
    "gdf[temp] = gdf[temp].apply(calc_prop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd1aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_idx(val, races):\n",
    "    race_idx = races.index(val)\n",
    "    return race_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530acb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf['true_race'] = gdf[races].idxmax(axis=1)\n",
    "gdf['true_race'] = gdf['true_race'].apply(lambda c: get_race_idx(c,races))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f58ef713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "      <th>true_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fleurime michel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franklin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grant cliatt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hassan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>king</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849821</th>\n",
       "      <td>zyzanski</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849822</th>\n",
       "      <td>zyzdryn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849823</th>\n",
       "      <td>zyznomyrsky</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849824</th>\n",
       "      <td>zzaman</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849825</th>\n",
       "      <td>zzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849826 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race           name_last  asian  hispanic  nh_black  nh_white  total_n  \\\n",
       "0        fleurime michel    0.0       0.0       1.0       0.0      1.0   \n",
       "1               franklin    0.0       0.0       1.0       0.0      1.0   \n",
       "2           grant cliatt    0.0       0.0       1.0       0.0      1.0   \n",
       "3                 hassan    1.0       0.0       0.0       0.0      1.0   \n",
       "4                   king    0.0       1.0       0.0       0.0      1.0   \n",
       "...                  ...    ...       ...       ...       ...      ...   \n",
       "849821          zyzanski    0.0       0.0       0.0       1.0      1.0   \n",
       "849822           zyzdryn    0.0       0.0       0.0       1.0      1.0   \n",
       "849823       zyznomyrsky    0.0       0.0       0.0       1.0      1.0   \n",
       "849824            zzaman    1.0       0.0       0.0       0.0      1.0   \n",
       "849825              zzie    0.0       0.0       0.0       1.0      1.0   \n",
       "\n",
       "race    true_race  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "849821          3  \n",
       "849822          3  \n",
       "849823          3  \n",
       "849824          0  \n",
       "849825          3  \n",
       "\n",
       "[849826 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa752d9",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2280b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212457, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df = gdf.groupby('true_race', group_keys=False).apply(lambda x: x.sample(frac=.25, random_state=10))\n",
    "proto_df.reset_index(inplace=True)\n",
    "proto_df.drop('index', axis=1, inplace=True)\n",
    "proto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46eca5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    129126\n",
       "1     53493\n",
       "2     22116\n",
       "0      7722\n",
       "Name: true_race, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our sampling has generated proportionate representation in all classes\n",
    "proto_df.true_race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3e7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 2\n",
    "feature_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26966915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# **********\n",
    "# **** CHANGE THIS TO FULL DATAFRAME WHEN READY FOR FULL DATASET ****\n",
    "a = vect.fit_transform(proto_df.name_last) \n",
    "tfidf = tfidf_transformer.fit_transform(a)\n",
    "# **********\n",
    "\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff327e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 778\n"
     ]
    }
   ],
   "source": [
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((a[:, c].sum(), b))\n",
    "\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3901ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20f8f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bi-grams from index of n-gram sequence\n",
    "proto_df['n_gram'] = np.array(proto_df.name_last.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "proto_df['n_gram'] = (sequence.pad_sequences(proto_df['n_gram'], maxlen=feature_len)).tolist()\n",
    "proto_df['tfidf'] = tfidf.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c841cf1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "      <th>true_race</th>\n",
       "      <th>n_gram</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adichirayil</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morillo encisco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 11, 12, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.40391457325644736,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hular</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuze</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balasingam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212452</th>\n",
       "      <td>robu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212453</th>\n",
       "      <td>redisch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212454</th>\n",
       "      <td>clute</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212455</th>\n",
       "      <td>matecki</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212456</th>\n",
       "      <td>frankfurt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212457 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race          name_last  asian  hispanic  nh_black  nh_white  total_n  \\\n",
       "0           adichirayil    1.0  0.000000       0.0  0.000000      1.0   \n",
       "1       morillo encisco    1.0  0.000000       0.0  0.000000      1.0   \n",
       "2                 hular    1.0  0.000000       0.0  0.000000      1.0   \n",
       "3                  fuze    0.5  0.000000       0.0  0.500000      1.0   \n",
       "4            balasingam    1.0  0.000000       0.0  0.000000      1.0   \n",
       "...                 ...    ...       ...       ...       ...      ...   \n",
       "212452             robu    0.0  0.000000       0.0  1.000000      1.0   \n",
       "212453          redisch    0.0  0.000000       0.0  1.000000      1.0   \n",
       "212454            clute    0.0  0.010638       0.0  0.989362      1.0   \n",
       "212455          matecki    0.0  0.000000       0.0  1.000000      1.0   \n",
       "212456        frankfurt    0.0  0.000000       0.0  1.000000      1.0   \n",
       "\n",
       "race    true_race                                             n_gram  \\\n",
       "0               0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1               0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 11, 12, ...   \n",
       "2               0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3               0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4               0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...           ...                                                ...   \n",
       "212452          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "212453          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "212454          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "212455          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "212456          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "race                                                tfidf  \n",
       "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1       [0.0, 0.0, 0.0, 0.0, 0.0, 0.40391457325644736,...  \n",
       "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                   ...  \n",
       "212452  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "212453  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "212454  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "212455  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "212456  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[212457 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2559767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (152968, 9)\n",
      "Validation set size: (38243, 9)\n",
      "Test set size: (21246, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(proto_df, test_size=.1)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=.2)\n",
    "print('Training set size: {}'.format(train_df.shape))\n",
    "print('Validation set size: {}'.format(valid_df.shape))\n",
    "print('Test set size: {}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c6f1912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(row, corpus_df, filter):\n",
    "    orig_vector = np.array(row['tfidf']).reshape(1,-1)\n",
    "    cossim = np.zeros(corpus_df.shape[0])\n",
    "    j = 0\n",
    "    for idx, row in corpus_df.iterrows():\n",
    "        sim = cosine_similarity(orig_vector,np.array(row['tfidf']).reshape(1,-1))\n",
    "        cossim[j] = sim\n",
    "        j+=1\n",
    "        \n",
    "    return np.argwhere(cossim >= filter).reshape(-2,).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "25379343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = cos_sim(valid_df.iloc[3], proto_df, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f2e8cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89200, 138562]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "134e0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_k(test_df, corpus_df, k):\n",
    "    for idx, row in test_df.iterrows():\n",
    "        indices = cos_sim(row, corpus_df, filter = .6)\n",
    "        filtered_corpus_df = corpus_df.iloc[indices]\n",
    "        # alternate filter = [pick top 5k]\n",
    "        #calculate levenshtein between i and filtered_corpus_df\n",
    "        #pick top k\n",
    "        #do weighted average and produce the results\n",
    "        print (filtered_corpus_df)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a69cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c9fbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since each row is a representation of a document, calculating the cosine similarity between the tf-idf matrix\n",
    "#  should give us the cosine similarity between each vector (row) with the other vectors (rows)\n",
    "#  the first row would be the cosine distance between vector 0 and vector 1,2,3,4.... n\n",
    "#  this produces a dense matrix of each vector relative to the others with the diagnols being \n",
    "#  a comparison to itself\n",
    "cos_sim = cosine_similarity(tfidf,tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bcaad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for all vectors that have a cosine similarity of <= 0.6 and > 0 \n",
    "mask = np.logical_and(cos_sim <=0.6, cos_sim > 0)\n",
    "sim_vector_idx = np.argwhere(cos_sim >=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99906257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most common 100 names\n",
    "#   returned results is a list of tuples of (record #, count)\n",
    "common_names = collections.Counter(sim_vector_idx[:,1]).most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92f669f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a list of of the names that should be passed on to Levenshtein Distance calculations\n",
    "common_names_list = []\n",
    "for i in range(len(common_names)):\n",
    "    common_names_list.append(common_names[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38153797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21519    rodriguez rodrigue\n",
       "57616             lodriguez\n",
       "11503          rodriguez c.\n",
       "53499             rodriguea\n",
       "82151      perez  rodriguez\n",
       "                ...        \n",
       "64570        rosero morales\n",
       "81175                artino\n",
       "11344                hassey\n",
       "16459     meadows-rodriguez\n",
       "29563                   nea\n",
       "Name: name_last, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df.iloc[common_names_list]['name_last']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967923a",
   "metadata": {},
   "source": [
    "# Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc7ac8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the DataFrame and resetting the index so that its from 0-xxxx\n",
    "leven_df = (proto_df.iloc[common_names_list]).copy()\n",
    "leven_df.reset_index(inplace=True)\n",
    "leven_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb013bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rodriguez rodrigue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lodriguez</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rodriguez c.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rodriguea</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perez  rodriguez</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>rosero morales</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>artino</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>hassey</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>meadows-rodriguez</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>nea</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race           name_last     asian  hispanic  nh_black  nh_white  total_n\n",
       "0     rodriguez rodrigue  0.000000  1.000000       0.0  0.000000      1.0\n",
       "1              lodriguez  0.000000  1.000000       0.0  0.000000      1.0\n",
       "2           rodriguez c.  0.000000  1.000000       0.0  0.000000      1.0\n",
       "3              rodriguea  0.000000  1.000000       0.0  0.000000      1.0\n",
       "4       perez  rodriguez  0.000000  1.000000       0.0  0.000000      1.0\n",
       "...                  ...       ...       ...       ...       ...      ...\n",
       "4995      rosero morales  0.000000  1.000000       0.0  0.000000      1.0\n",
       "4996              artino  0.000000  0.000000       0.0  1.000000      1.0\n",
       "4997              hassey  0.034483  0.034483       0.0  0.931034      1.0\n",
       "4998   meadows-rodriguez  0.000000  0.000000       0.0  1.000000      1.0\n",
       "4999                 nea  0.000000  0.000000       0.0  1.000000      1.0\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leven_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65ed2e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [25:18,  3.29it/s] \n"
     ]
    }
   ],
   "source": [
    "if (REGEN):\n",
    "    # Creating Numpy Array to hold results\n",
    "    dim = leven_df.shape[0]\n",
    "\n",
    "    lev_dist = np.zeros((dim,dim))\n",
    "    for idx, row1 in tqdm(leven_df.iterrows()):\n",
    "        for j in range (idx, dim):\n",
    "            if (idx == j):\n",
    "                continue\n",
    "            else:\n",
    "                lev_dist[idx,j] = lv.distance(row1['name_last'],leven_df.iloc[j]['name_last'])\n",
    "else:\n",
    "    lev_dist = pd.read_csv('lev_distance_1per.csv').to_numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de2a531d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.,  8., ..., 17., 11., 17.],\n",
       "       [ 0.,  0.,  4., ...,  8.,  9.,  8.],\n",
       "       [ 0.,  0.,  0., ..., 11., 11., 11.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0., 14.,  5.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., 15.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# half filled out matrix\n",
    "lev_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17a61f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out the bottom portion of the matrix\n",
    "#  i.e. the distance between name[123] & name[345] is the\n",
    "#  same as string[345] & name[123]\n",
    "\n",
    "if (REGEN):\n",
    "    for i in range(dim):\n",
    "        for j in range (i, dim):\n",
    "            if (i == j):\n",
    "                continue\n",
    "            else:\n",
    "                lev_dist[j,i] = lev_dist[i,j]\n",
    "    # Now the matrix is mirrored\n",
    "    lev_dist.tofile('lev_distance_1per.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59f894",
   "metadata": {},
   "source": [
    "# Find K smallest values\n",
    "i.e. the nearest k neighbors in our vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1359c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy (name_df, levenstein_dist, k):\n",
    "    # Get the nearest k values for the string\n",
    "    #   we add +1 since 0 (the string itself)\n",
    "    #   will be present in the diagnal value\n",
    "    k +=1 \n",
    "    values = np.argpartition(levenstein_dist, (k))\n",
    "    final_pred = []\n",
    "    for i in tqdm(range(levenstein_dist.shape[0])):\n",
    "        max_value = np.max(levenstein_dist[i][values[i][:k]])\n",
    "        mask = (levenstein_dist[i] <= max_value) & (levenstein_dist[i] > 0)\n",
    "        out = np.argwhere(mask)\n",
    "        total_sum =  (name_df.iloc[out.reshape(-1)]['total_n'].sum())\n",
    "        pred_white = (name_df.iloc[out.reshape(-1)]['nh_white'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_black = (name_df.iloc[out.reshape(-1)]['nh_black'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_hispanic = (name_df.iloc[out.reshape(-1)]['hispanic'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_asian = (name_df.iloc[out.reshape(-1)]['asian'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        predictions = [pred_asian, pred_hispanic, pred_black, pred_white]\n",
    "        final_pred.append(races[predictions.index(max(predictions))])\n",
    "    name_df['true_race'] = name_df[races].idxmax(axis=1)\n",
    "    name_df['pred'] = final_pred\n",
    "    return (classification_report(name_df['true_race'],name_df['pred']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc74cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_metrics = {\n",
    "    3:0,\n",
    "    5:0,\n",
    "    7:0,\n",
    "    10:0,\n",
    "    15:0,\n",
    "    20:0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6d06e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(proto_df.sample(frac=0.1, random_state=10), test_size=0.1)\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c881a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 305.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.14      0.01      0.02        89\n",
      "    hispanic       0.95      0.89      0.92      2427\n",
      "    nh_black       0.62      0.40      0.48       295\n",
      "    nh_white       0.81      0.93      0.86      2189\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.63      0.56      0.57      5000\n",
      "weighted avg       0.85      0.86      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 308.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=5:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        89\n",
      "    hispanic       0.96      0.89      0.92      2427\n",
      "    nh_black       0.67      0.38      0.49       295\n",
      "    nh_white       0.80      0.94      0.87      2189\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.61      0.55      0.57      5000\n",
      "weighted avg       0.85      0.87      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 311.04it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=7:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        89\n",
      "    hispanic       0.96      0.88      0.92      2427\n",
      "    nh_black       0.69      0.38      0.49       295\n",
      "    nh_white       0.80      0.95      0.87      2189\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.61      0.55      0.57      5000\n",
      "weighted avg       0.86      0.87      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 304.59it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=10:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        89\n",
      "    hispanic       0.96      0.88      0.92      2427\n",
      "    nh_black       0.69      0.38      0.49       295\n",
      "    nh_white       0.80      0.95      0.87      2189\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.61      0.55      0.57      5000\n",
      "weighted avg       0.85      0.86      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:15<00:00, 316.47it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=15:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        89\n",
      "    hispanic       0.96      0.88      0.92      2427\n",
      "    nh_black       0.67      0.38      0.48       295\n",
      "    nh_white       0.79      0.95      0.86      2189\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.61      0.55      0.57      5000\n",
      "weighted avg       0.85      0.86      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:17<00:00, 293.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=20:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        89\n",
      "    hispanic       0.96      0.87      0.91      2427\n",
      "    nh_black       0.67      0.38      0.49       295\n",
      "    nh_white       0.79      0.95      0.86      2189\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.61      0.55      0.57      5000\n",
      "weighted avg       0.85      0.86      0.85      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for value, key in enumerate (k_metrics):\n",
    "    value = get_accuracy (leven_df, lev_dist, key)\n",
    "    print ('For k={}:\\n {}\\n\\n-----------------------\\n'.format(key,value))\n",
    "    k_metrics[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b884b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (name_df, corp_df, k):\n",
    "    corp_name = corp_df['name_last']\n",
    "\n",
    "    # Calculate the Levenshtein distance for the test set that we are trying to predict\n",
    "    test_lev_dist = np.zeros((name_df.shape[0],corp_df.shape[0]))\n",
    "    for idx, row1 in tqdm(name_df.iterrows()):\n",
    "        for j in range(corp_df.shape[0]):\n",
    "            test_lev_dist[idx,j] = lv.distance(row1['name_last'],corp_df.iloc[j]['name_last'])\n",
    "    \n",
    "    # Get accuracy of the model on the test set\n",
    "    #   - taking the levenshtein distance calculated from test names to corpus names\n",
    "    #   - finding the nearest training names to the test names\n",
    "    #   - predicting the test race based on the training names\n",
    "    k +=1 \n",
    "    values = np.argpartition(test_lev_dist, (k))\n",
    "    final_pred = []\n",
    "    for i in tqdm(range(test_lev_dist.shape[0])):\n",
    "        max_value = np.max(test_lev_dist[i][values[i][:k]])\n",
    "        mask = (test_lev_dist[i] <= max_value) & (test_lev_dist[i] > 0)\n",
    "        out = np.argwhere(mask)\n",
    "        total_sum =  (corp_df.iloc[out.reshape(-1)]['total_n'].sum())\n",
    "        pred_white = (corp_df.iloc[out.reshape(-1)]['nh_white'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_black = (corp_df.iloc[out.reshape(-1)]['nh_black'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_hispanic = (corp_df.iloc[out.reshape(-1)]['hispanic'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_asian = (corp_df.iloc[out.reshape(-1)]['asian'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        predictions = [pred_asian, pred_hispanic, pred_black, pred_white]\n",
    "        final_pred.append(races[predictions.index(max(predictions))])\n",
    "        \n",
    "    name_df['true_race'] = name_df[races].idxmax(axis=1)\n",
    "    name_df['pred'] = final_pred\n",
    "    return (classification_report(name_df['true_race'],name_df['pred'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f43bfd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "850it [09:06,  1.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [00:03<00:00, 248.55it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_perf = predict(test_df, leven_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ff749cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        28\n",
      "    hispanic       0.69      0.63      0.66       206\n",
      "    nh_black       0.62      0.10      0.17       102\n",
      "    nh_white       0.72      0.91      0.81       514\n",
      "\n",
      "    accuracy                           0.72       850\n",
      "   macro avg       0.51      0.41      0.41       850\n",
      "weighted avg       0.68      0.72      0.67       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 1  2  3\n",
    "1 .1 .2 .7\n",
    "2 .1 .3 .7\n",
    "3 .7 .2 .1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
