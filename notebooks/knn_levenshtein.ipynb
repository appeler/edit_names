{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a46d456",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece8afa",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c04226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import Levenshtein as lv\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer                                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True when you want to regenerate the Levenshtein Distance\n",
    "#  otherwise will load csv file\n",
    "REGEN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91326fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walker</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>palmer</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mc cleod</td>\n",
       "      <td>nh_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scarborough</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walker</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653888</th>\n",
       "      <td>philpott</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653889</th>\n",
       "      <td>walters</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653890</th>\n",
       "      <td>sawyer</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653891</th>\n",
       "      <td>thomas</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653893</th>\n",
       "      <td>bruner</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12989098 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name_last      race\n",
       "0              walker  nh_white\n",
       "1              palmer  nh_white\n",
       "2            mc cleod  nh_black\n",
       "3         scarborough  nh_white\n",
       "4              walker  nh_white\n",
       "...               ...       ...\n",
       "13653888     philpott  nh_white\n",
       "13653889      walters  nh_white\n",
       "13653890       sawyer  nh_white\n",
       "13653891       thomas  nh_white\n",
       "13653893       bruner  nh_white\n",
       "\n",
       "[12989098 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Florida voter file\n",
    "df = pd.read_csv('../dataverse_files/fl_reg_name_race.csv.gz')\n",
    "df.dropna(subset=['name_last'], inplace=True)\n",
    "\n",
    "sdf = df[df.race.isin(['multi_racial', 'native_indian', 'other', 'unknown']) == False]\n",
    "del df\n",
    "\n",
    "# Setting consistent case for names\n",
    "sdf['name_last'] = sdf.name_last.str.lower()\n",
    "\n",
    "# Remove unrequired first name\n",
    "sdf.drop('name_first', axis=1, inplace=True)\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38523827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nh_white    8714118\n",
       "hispanic    2174408\n",
       "nh_black    1847266\n",
       "asian        253306\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the different races filtered\n",
    "sdf.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de025d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the count of each name & race combination\n",
    "gdf = sdf.groupby(['name_last','race'], as_index=False)['race'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f243b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pivot table so that each name has a count of the # of races with that last name\n",
    "gdf = gdf.pivot_table(values='count', columns='race',index='name_last')\n",
    "\n",
    "# Converting NaN to zeros since that means there is no one that identifies with that race with that last name\n",
    "gdf = gdf.fillna(0)\n",
    "\n",
    "# Getting the totals of each last name\n",
    "gdf['total_n'] = gdf.sum(axis=1)\n",
    "gdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0f7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fleurime michel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franklin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grant cliatt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hassan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>king</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>williams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0kharitonenko</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1amirthanayagam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77348 dancing rochanavibhata</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a de feria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a de fernandez</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a f r stephenson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a felix</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a ghaffar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "race                     name_last  asian  hispanic  nh_black  nh_white  \\\n",
       "0                  fleurime michel    0.0       0.0       1.0       0.0   \n",
       "1                         franklin    0.0       0.0       1.0       0.0   \n",
       "2                     grant cliatt    0.0       0.0       1.0       0.0   \n",
       "3                           hassan    1.0       0.0       0.0       0.0   \n",
       "4                             king    0.0       1.0       0.0       0.0   \n",
       "5                         williams    0.0       0.0       0.0       1.0   \n",
       "6                    0kharitonenko    0.0       0.0       0.0       1.0   \n",
       "7                  1amirthanayagam    1.0       0.0       0.0       0.0   \n",
       "8                               4r    0.0       0.0       0.0       1.0   \n",
       "9     77348 dancing rochanavibhata    1.0       0.0       0.0       0.0   \n",
       "10                      a de feria    0.0       1.0       0.0       0.0   \n",
       "11                  a de fernandez    0.0       1.0       0.0       0.0   \n",
       "12                a f r stephenson    0.0       0.0       0.0       1.0   \n",
       "13                         a felix    0.0       1.0       0.0       0.0   \n",
       "14                       a ghaffar    0.0       0.0       0.0       1.0   \n",
       "\n",
       "race  total_n  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         1.0  \n",
       "6         1.0  \n",
       "7         1.0  \n",
       "8         1.0  \n",
       "9         1.0  \n",
       "10        1.0  \n",
       "11        1.0  \n",
       "12        1.0  \n",
       "13        1.0  \n",
       "14        1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63880fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian', 'hispanic', 'nh_black', 'nh_white']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = sorted(sdf.race.unique().tolist())\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee82c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prop(row):\n",
    "    total = row['total_n']\n",
    "    values = [(i/total) for i in row]\n",
    "    return pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cb18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of people with a particular last name\n",
    "#  that identify with one of the 4 races\n",
    "temp = races.copy()\n",
    "temp.append('total_n')\n",
    "\n",
    "gdf[temp] = gdf[temp].apply(calc_prop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58ef713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fleurime michel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franklin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grant cliatt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hassan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>king</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849821</th>\n",
       "      <td>zyzanski</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849822</th>\n",
       "      <td>zyzdryn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849823</th>\n",
       "      <td>zyznomyrsky</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849824</th>\n",
       "      <td>zzaman</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849825</th>\n",
       "      <td>zzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849826 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race           name_last  asian  hispanic  nh_black  nh_white  total_n\n",
       "0        fleurime michel    0.0       0.0       1.0       0.0      1.0\n",
       "1               franklin    0.0       0.0       1.0       0.0      1.0\n",
       "2           grant cliatt    0.0       0.0       1.0       0.0      1.0\n",
       "3                 hassan    1.0       0.0       0.0       0.0      1.0\n",
       "4                   king    0.0       1.0       0.0       0.0      1.0\n",
       "...                  ...    ...       ...       ...       ...      ...\n",
       "849821          zyzanski    0.0       0.0       0.0       1.0      1.0\n",
       "849822           zyzdryn    0.0       0.0       0.0       1.0      1.0\n",
       "849823       zyznomyrsky    0.0       0.0       0.0       1.0      1.0\n",
       "849824            zzaman    1.0       0.0       0.0       0.0      1.0\n",
       "849825              zzie    0.0       0.0       0.0       1.0      1.0\n",
       "\n",
       "[849826 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa752d9",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2280b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84983, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df = gdf.sample(frac=0.1, random_state=10)\n",
    "proto_df.reset_index(inplace=True)\n",
    "proto_df.drop('index', axis=1, inplace=True)\n",
    "proto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2d8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 2\n",
    "feature_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d6619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# **********\n",
    "# **** CHANGE THIS TO FULL DATAFRAME WHEN READY FOR FULL DATASET ****\n",
    "a = vect.fit_transform(proto_df.name_last) \n",
    "tfidf = tfidf_transformer.fit_transform(a)\n",
    "# **********\n",
    "\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f4be1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 731\n"
     ]
    }
   ],
   "source": [
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((a[:, c].sum(), b))\n",
    "\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77fb9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d26ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bi-grams from index of n-gram sequence\n",
    "proto_df['n_gram'] = np.array(proto_df.name_last.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "proto_df['n_gram'] = (sequence.pad_sequences(proto_df['n_gram'], maxlen=feature_len)).tolist()\n",
    "proto_df['tfidf'] = tfidf.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c935f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "      <th>n_gram</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bojin</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>owens-harvey</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anelis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clavel rivera</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 21...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ley</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>0.241993</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.708185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84978</th>\n",
       "      <td>cioletti</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84979</th>\n",
       "      <td>montillano</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84980</th>\n",
       "      <td>hershbein</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84981</th>\n",
       "      <td>delvalle rodriguez</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 72, 17, 181, 182, 43,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84982</th>\n",
       "      <td>brownsell</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84983 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race            name_last     asian  hispanic  nh_black  nh_white  total_n  \\\n",
       "0                   bojin  0.000000  0.000000  0.000000  1.000000      1.0   \n",
       "1            owens-harvey  0.000000  0.000000  1.000000  0.000000      1.0   \n",
       "2                  anelis  0.000000  0.000000  1.000000  0.000000      1.0   \n",
       "3           clavel rivera  0.000000  1.000000  0.000000  0.000000      1.0   \n",
       "4                     ley  0.042705  0.241993  0.007117  0.708185      1.0   \n",
       "...                   ...       ...       ...       ...       ...      ...   \n",
       "84978            cioletti  0.000000  0.000000  0.000000  1.000000      1.0   \n",
       "84979          montillano  1.000000  0.000000  0.000000  0.000000      1.0   \n",
       "84980           hershbein  0.000000  0.000000  0.000000  1.000000      1.0   \n",
       "84981  delvalle rodriguez  0.000000  1.000000  0.000000  0.000000      1.0   \n",
       "84982           brownsell  0.000000  0.000000  0.000000  1.000000      1.0   \n",
       "\n",
       "race                                              n_gram  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 21...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "84978  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "84979  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "84980  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "84981  [0, 0, 0, 0, 0, 0, 0, 0, 72, 17, 181, 182, 43,...   \n",
       "84982  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "race                                               tfidf  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "84978  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "84979  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "84980  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "84981  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "84982  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[84983 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc329e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since each row is a representation of a document, calculating the cosine similarity between the tf-idf matrix\n",
    "#  should give us the cosine similarity between each vector (row) with the other vectors (rows)\n",
    "#  the first row would be the cosine distance between vector 0 and vector 1,2,3,4.... n\n",
    "#  this produces a dense matrix of each vector relative to the others with the diagnols being \n",
    "#  a comparison to itself\n",
    "cos_sim = cosine_similarity(tfidf,tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c448f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for all vectors that have a cosine similarity of <= 0.6 and > 0 \n",
    "mask = np.logical_and(cos_sim <=0.6, cos_sim > 0)\n",
    "sim_vector_idx = np.argwhere(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6fe28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most common 100 names\n",
    "#   returned results is a list of tuples of (record #, count)\n",
    "common_names = collections.Counter(sim_vector_idx[:,1]).most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c94839c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a list of of the names that should be passed on to Levenshtein Distance calculations\n",
    "common_names_list = []\n",
    "for i in range(len(common_names)):\n",
    "    common_names_list.append(common_names[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84ef6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67132     calderon-candelario\n",
       "30044    hernandez-valladares\n",
       "17271     blanchard caballero\n",
       "66949    manchester-arguelles\n",
       "64591    martinez castellanos\n",
       "                 ...         \n",
       "2162          harris-kaechele\n",
       "79887         molina casanova\n",
       "10076           milian dardon\n",
       "21291          aluli imberman\n",
       "67406          truman-vollmer\n",
       "Name: name_last, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df.iloc[common_names_list]['name_last']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967923a",
   "metadata": {},
   "source": [
    "# Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc7ac8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the DataFrame and resetting the index so that its from 0-xxxx\n",
    "leven_df = (proto_df.iloc[common_names_list]).copy()\n",
    "leven_df.reset_index(inplace=True)\n",
    "leven_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb013bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>name_last</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calderon-candelario</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hernandez-valladares</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blanchard caballero</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manchester-arguelles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>martinez castellanos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>harris-kaechele</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>molina casanova</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>milian dardon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>aluli imberman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>truman-vollmer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race             name_last  asian  hispanic  nh_black  nh_white  total_n\n",
       "0      calderon-candelario    0.0       1.0       0.0       0.0      1.0\n",
       "1     hernandez-valladares    0.0       1.0       0.0       0.0      1.0\n",
       "2      blanchard caballero    0.0       1.0       0.0       0.0      1.0\n",
       "3     manchester-arguelles    0.0       0.0       0.0       1.0      1.0\n",
       "4     martinez castellanos    0.0       1.0       0.0       0.0      1.0\n",
       "...                    ...    ...       ...       ...       ...      ...\n",
       "4995       harris-kaechele    0.0       0.0       0.0       1.0      1.0\n",
       "4996       molina casanova    0.0       1.0       0.0       0.0      1.0\n",
       "4997         milian dardon    0.0       1.0       0.0       0.0      1.0\n",
       "4998        aluli imberman    0.0       0.0       0.0       1.0      1.0\n",
       "4999        truman-vollmer    0.0       0.0       0.0       1.0      1.0\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leven_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65ed2e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [24:49,  3.36it/s] \n"
     ]
    }
   ],
   "source": [
    "if (REGEN):\n",
    "    # Creating Numpy Array to hold results\n",
    "    dim = leven_df.shape[0]\n",
    "\n",
    "    lev_dist = np.zeros((dim,dim))\n",
    "    for idx, row1 in tqdm(leven_df.iterrows()):\n",
    "        for j in range (idx, dim):\n",
    "            if (idx == j):\n",
    "                continue\n",
    "            else:\n",
    "                lev_dist[idx,j] = lv.distance(row1['name_last'],leven_df.iloc[j]['name_last'])\n",
    "else:\n",
    "    lev_dist = pd.read_csv('lev_distance_1per.csv').to_numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de2a531d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 15., 14., ..., 14., 16., 16.],\n",
       "       [ 0.,  0., 15., ..., 16., 18., 13.],\n",
       "       [ 0.,  0.,  0., ..., 15., 16., 15.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0., 10., 12.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., 12.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# half filled out matrix\n",
    "lev_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17a61f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out the bottom portion of the matrix\n",
    "#  i.e. the distance between name[123] & name[345] is the\n",
    "#  same as string[345] & name[123]\n",
    "\n",
    "if (REGEN):\n",
    "    for i in range(dim):\n",
    "        for j in range (i, dim):\n",
    "            if (i == j):\n",
    "                continue\n",
    "            else:\n",
    "                lev_dist[j,i] = lev_dist[i,j]\n",
    "    # Now the matrix is mirrored\n",
    "    lev_dist.tofile('lev_distance_1per.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59f894",
   "metadata": {},
   "source": [
    "# Find K smallest values\n",
    "i.e. the nearest k neighbors in our vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1359c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy (name_df, levenstein_dist, k):\n",
    "    # Get the nearest k values for the string\n",
    "    #   we add +1 since 0 (the string itself)\n",
    "    #   will be present in the diagnal value\n",
    "    k +=1 \n",
    "    values = np.argpartition(levenstein_dist, (k))\n",
    "    final_pred = []\n",
    "    for i in tqdm(range(levenstein_dist.shape[0])):\n",
    "        max_value = np.max(levenstein_dist[i][values[i][:k]])\n",
    "        mask = (levenstein_dist[i] <= max_value) & (levenstein_dist[i] > 0)\n",
    "        out = np.argwhere(mask)\n",
    "        total_sum =  (name_df.iloc[out.reshape(-1)]['total_n'].sum())\n",
    "        pred_white = (name_df.iloc[out.reshape(-1)]['nh_white'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_black = (name_df.iloc[out.reshape(-1)]['nh_black'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_hispanic = (name_df.iloc[out.reshape(-1)]['hispanic'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_asian = (name_df.iloc[out.reshape(-1)]['asian'] * name_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        predictions = [pred_asian, pred_hispanic, pred_black, pred_white]\n",
    "        final_pred.append(races[predictions.index(max(predictions))])\n",
    "    name_df['true_race'] = name_df[races].idxmax(axis=1)\n",
    "    name_df['pred'] = final_pred\n",
    "    return (classification_report(name_df['true_race'],name_df['pred']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc74cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_metrics = {\n",
    "    3:0,\n",
    "    5:0,\n",
    "    7:0,\n",
    "    10:0,\n",
    "    15:0,\n",
    "    20:0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cab12dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(proto_df.sample(frac=0.1, random_state=10), test_size=0.1)\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df.drop(['index','n_gram','tfidf'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c881a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 300.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.81      0.98      0.89      3393\n",
      "    nh_black       0.49      0.30      0.37       450\n",
      "    nh_white       0.67      0.38      0.48      1121\n",
      "\n",
      "    accuracy                           0.78      5000\n",
      "   macro avg       0.49      0.41      0.44      5000\n",
      "weighted avg       0.75      0.78      0.74      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 308.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=5:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.80      0.98      0.88      3393\n",
      "    nh_black       0.50      0.24      0.33       450\n",
      "    nh_white       0.67      0.38      0.48      1121\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.49      0.40      0.42      5000\n",
      "weighted avg       0.74      0.77      0.74      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 298.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=7:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.80      0.99      0.88      3393\n",
      "    nh_black       0.51      0.20      0.29       450\n",
      "    nh_white       0.67      0.37      0.48      1121\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.50      0.39      0.41      5000\n",
      "weighted avg       0.74      0.77      0.73      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 310.90it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=10:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.79      0.99      0.88      3393\n",
      "    nh_black       0.49      0.16      0.24       450\n",
      "    nh_white       0.67      0.36      0.47      1121\n",
      "\n",
      "    accuracy                           0.76      5000\n",
      "   macro avg       0.49      0.38      0.40      5000\n",
      "weighted avg       0.73      0.76      0.72      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:17<00:00, 285.26it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=15:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.78      0.99      0.87      3393\n",
      "    nh_black       0.51      0.10      0.17       450\n",
      "    nh_white       0.67      0.34      0.45      1121\n",
      "\n",
      "    accuracy                           0.76      5000\n",
      "   macro avg       0.49      0.36      0.37      5000\n",
      "weighted avg       0.72      0.76      0.71      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:16<00:00, 305.90it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=20:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.76      0.99      0.86      3393\n",
      "    nh_black       0.52      0.07      0.12       450\n",
      "    nh_white       0.67      0.32      0.43      1121\n",
      "\n",
      "    accuracy                           0.75      5000\n",
      "   macro avg       0.49      0.35      0.35      5000\n",
      "weighted avg       0.71      0.75      0.69      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:17<00:00, 290.23it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=100:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.70      1.00      0.82      3393\n",
      "    nh_black       1.00      0.00      0.00       450\n",
      "    nh_white       0.71      0.11      0.20      1121\n",
      "\n",
      "    accuracy                           0.70      5000\n",
      "   macro avg       0.60      0.28      0.26      5000\n",
      "weighted avg       0.73      0.70      0.60      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:18<00:00, 268.54it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=300:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.68      1.00      0.81      3393\n",
      "    nh_black       0.00      0.00      0.00       450\n",
      "    nh_white       0.86      0.01      0.01      1121\n",
      "\n",
      "    accuracy                           0.68      5000\n",
      "   macro avg       0.38      0.25      0.20      5000\n",
      "weighted avg       0.65      0.68      0.55      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:22<00:00, 224.50it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=500:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        36\n",
      "    hispanic       0.68      1.00      0.81      3393\n",
      "    nh_black       0.00      0.00      0.00       450\n",
      "    nh_white       0.00      0.00      0.00      1121\n",
      "\n",
      "    accuracy                           0.68      5000\n",
      "   macro avg       0.17      0.25      0.20      5000\n",
      "weighted avg       0.46      0.68      0.55      5000\n",
      "\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for value, key in enumerate (k_metrics):\n",
    "    value = get_accuracy (leven_df, lev_dist, key)\n",
    "    print ('For k={}:\\n {}\\n\\n-----------------------\\n'.format(key,value))\n",
    "    k_metrics[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b884b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (name_df, corp_df, k):\n",
    "    corp_name = corp_df['name_last']\n",
    "\n",
    "    # Calculate the Levenshtein distance for the test set that we are trying to predict\n",
    "    test_lev_dist = np.zeros((name_df.shape[0],corp_df.shape[0]))\n",
    "    for idx, row1 in tqdm(name_df.iterrows()):\n",
    "        for j in range(corp_df.shape[0]):\n",
    "            test_lev_dist[idx,j] = lv.distance(row1['name_last'],corp_df.iloc[j]['name_last'])\n",
    "    \n",
    "    # Get accuracy of the model on the test set\n",
    "    #   - taking the levenshtein distance calculated from test names to corpus names\n",
    "    #   - finding the nearest training names to the test names\n",
    "    #   - predicting the test race based on the training names\n",
    "    k +=1 \n",
    "    values = np.argpartition(test_lev_dist, (k))\n",
    "    final_pred = []\n",
    "    for i in tqdm(range(test_lev_dist.shape[0])):\n",
    "        max_value = np.max(test_lev_dist[i][values[i][:k]])\n",
    "        mask = (test_lev_dist[i] <= max_value) & (test_lev_dist[i] > 0)\n",
    "        out = np.argwhere(mask)\n",
    "        total_sum =  (corp_df.iloc[out.reshape(-1)]['total_n'].sum())\n",
    "        pred_white = (corp_df.iloc[out.reshape(-1)]['nh_white'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_black = (corp_df.iloc[out.reshape(-1)]['nh_black'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_hispanic = (corp_df.iloc[out.reshape(-1)]['hispanic'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        pred_asian = (corp_df.iloc[out.reshape(-1)]['asian'] * corp_df.iloc[out.reshape(-1)]['total_n']).sum() / total_sum\n",
    "        predictions = [pred_asian, pred_hispanic, pred_black, pred_white]\n",
    "        final_pred.append(races[predictions.index(max(predictions))])\n",
    "        \n",
    "    name_df['true_race'] = name_df[races].idxmax(axis=1)\n",
    "    name_df['pred'] = final_pred\n",
    "    return (classification_report(name_df['true_race'],name_df['pred'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f43bfd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "850it [08:52,  1.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [00:02<00:00, 314.89it/s]\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_perf = predict(test_df, leven_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd6a7a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.00      0.00      0.00        28\n",
      "    hispanic       0.53      0.79      0.63       212\n",
      "    nh_black       0.79      0.11      0.19        99\n",
      "    nh_white       0.76      0.77      0.76       511\n",
      "\n",
      "    accuracy                           0.67       850\n",
      "   macro avg       0.52      0.42      0.40       850\n",
      "weighted avg       0.68      0.67      0.64       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bcc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
