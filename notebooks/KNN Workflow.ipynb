{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a46d456",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece8afa",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c04226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91326fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walker</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Palmer</td>\n",
       "      <td>Alton</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mc Cleod</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>nh_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Dale</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walker</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653888</th>\n",
       "      <td>Philpott</td>\n",
       "      <td>April</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653889</th>\n",
       "      <td>Walters</td>\n",
       "      <td>William</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653890</th>\n",
       "      <td>Sawyer</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653891</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>Janine</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653893</th>\n",
       "      <td>Bruner</td>\n",
       "      <td>Jeb</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12989098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name_last name_first      race\n",
       "0              Walker  Elizabeth  nh_white\n",
       "1              Palmer      Alton  nh_white\n",
       "2            Mc Cleod     Alicia  nh_black\n",
       "3         Scarborough       Dale  nh_white\n",
       "4              Walker     Daniel  nh_white\n",
       "...               ...        ...       ...\n",
       "13653888     Philpott      April  nh_white\n",
       "13653889      Walters    William  nh_white\n",
       "13653890       Sawyer    Matthew  nh_white\n",
       "13653891       Thomas     Janine  nh_white\n",
       "13653893       Bruner        Jeb  nh_white\n",
       "\n",
       "[12989098 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Florida voter file\n",
    "df = pd.read_csv('../dataverse_files/fl_reg_name_race.csv.gz')\n",
    "df.dropna(subset=['name_first', 'name_last'], inplace=True)\n",
    "\n",
    "sdf = df[df.race.isin(['multi_racial', 'native_indian', 'other', 'unknown']) == False]\n",
    "del df\n",
    "\n",
    "# Setting consistent case for names\n",
    "sdf['name_first'] = sdf.name_first.str.title()\n",
    "sdf['name_last'] = sdf.name_last.str.title()\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38523827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nh_white    8714118\n",
       "hispanic    2174408\n",
       "nh_black    1847266\n",
       "asian        253306\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the different races filtered\n",
    "sdf.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de025d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the count of each name & race combination\n",
    "gdf = sdf.groupby(['name_last','race'], as_index=False)['race'].agg(['count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f243b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pivot table so that each name has a count of the # of races with that last name\n",
    "gdf = gdf.pivot_table(values='count', columns='race',index='name_last')\n",
    "\n",
    "# Converting NaN to zeros since that means there is no one that identifies with that race with that last name\n",
    "gdf = gdf.fillna(0)\n",
    "\n",
    "# Getting the totals of each last name\n",
    "gdf['total_n'] = gdf.sum(axis=1)\n",
    "\n",
    "gdf['total_norm'] = gdf['total_n']/np.max(gdf['total_n'])\n",
    "gdf['name_last'] = gdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0f7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "      <th>total_norm</th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_last</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fleurime Michel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Fleurime Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franklin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Franklin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant Cliatt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Grant Cliatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hassan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Hassan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0Kharitonenko</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0Kharitonenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Amirthanayagam</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1Amirthanayagam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>4R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77348 Dancing Rochanavibhata</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>77348 Dancing Rochanavibhata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A De Feria</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>A De Feria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A De Fernandez</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>A De Fernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A F R Stephenson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>A F R Stephenson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Felix</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>A Felix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Ghaffar</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>A Ghaffar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "race                          asian  hispanic  nh_black  nh_white  total_n  \\\n",
       "name_last                                                                    \n",
       " Fleurime Michel                0.0       0.0       1.0       0.0      1.0   \n",
       " Franklin                       0.0       0.0       1.0       0.0      1.0   \n",
       " Grant Cliatt                   0.0       0.0       1.0       0.0      1.0   \n",
       " Hassan                         1.0       0.0       0.0       0.0      1.0   \n",
       " King                           0.0       1.0       0.0       0.0      1.0   \n",
       " Williams                       0.0       0.0       0.0       1.0      1.0   \n",
       "0Kharitonenko                   0.0       0.0       0.0       1.0      1.0   \n",
       "1Amirthanayagam                 1.0       0.0       0.0       0.0      1.0   \n",
       "4R                              0.0       0.0       0.0       1.0      1.0   \n",
       "77348 Dancing Rochanavibhata    1.0       0.0       0.0       0.0      1.0   \n",
       "A De Feria                      0.0       1.0       0.0       0.0      1.0   \n",
       "A De Fernandez                  0.0       1.0       0.0       0.0      1.0   \n",
       "A F R Stephenson                0.0       0.0       0.0       1.0      1.0   \n",
       "A Felix                         0.0       1.0       0.0       0.0      1.0   \n",
       "A Ghaffar                       0.0       0.0       0.0       1.0      1.0   \n",
       "\n",
       "race                          total_norm                     name_last  \n",
       "name_last                                                               \n",
       " Fleurime Michel                 0.00001               Fleurime Michel  \n",
       " Franklin                        0.00001                      Franklin  \n",
       " Grant Cliatt                    0.00001                  Grant Cliatt  \n",
       " Hassan                          0.00001                        Hassan  \n",
       " King                            0.00001                          King  \n",
       " Williams                        0.00001                      Williams  \n",
       "0Kharitonenko                    0.00001                 0Kharitonenko  \n",
       "1Amirthanayagam                  0.00001               1Amirthanayagam  \n",
       "4R                               0.00001                            4R  \n",
       "77348 Dancing Rochanavibhata     0.00001  77348 Dancing Rochanavibhata  \n",
       "A De Feria                       0.00001                    A De Feria  \n",
       "A De Fernandez                   0.00001                A De Fernandez  \n",
       "A F R Stephenson                 0.00001              A F R Stephenson  \n",
       "A Felix                          0.00001                       A Felix  \n",
       "A Ghaffar                        0.00001                     A Ghaffar  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63880fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nh_white', 'nh_black', 'hispanic', 'asian']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = sdf.race.unique().tolist()\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee82c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prop(row):\n",
    "    total = row['total_n']\n",
    "    values = [(i/total) for i in row]\n",
    "    return pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59cb18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nh_white', 'nh_black', 'hispanic', 'asian', 'total_n']\n"
     ]
    }
   ],
   "source": [
    "temp = races\n",
    "temp.append('total_n')\n",
    "print(temp)\n",
    "gdf[races] = gdf[temp].apply(calc_prop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58ef713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>race</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>total_n</th>\n",
       "      <th>total_norm</th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_last</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fleurime Michel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Fleurime Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franklin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Franklin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant Cliatt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Grant Cliatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hassan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Hassan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zyzanski</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Zyzanski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zyzdryn</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>Zyzdryn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zyznomyrsky</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Zyznomyrsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zzaman</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Zzaman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zzie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Zzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849826 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "race              asian  hispanic  nh_black  nh_white  total_n  total_norm  \\\n",
       "name_last                                                                    \n",
       " Fleurime Michel    0.0       0.0       1.0       0.0      1.0    0.000010   \n",
       " Franklin           0.0       0.0       1.0       0.0      1.0    0.000010   \n",
       " Grant Cliatt       0.0       0.0       1.0       0.0      1.0    0.000010   \n",
       " Hassan             1.0       0.0       0.0       0.0      1.0    0.000010   \n",
       " King               0.0       1.0       0.0       0.0      1.0    0.000010   \n",
       "...                 ...       ...       ...       ...      ...         ...   \n",
       "Zyzanski            0.0       0.0       0.0       1.0      1.0    0.000010   \n",
       "Zyzdryn             0.0       0.0       0.0       1.0      1.0    0.000019   \n",
       "Zyznomyrsky         0.0       0.0       0.0       1.0      1.0    0.000010   \n",
       "Zzaman              1.0       0.0       0.0       0.0      1.0    0.000010   \n",
       "Zzie                0.0       0.0       0.0       1.0      1.0    0.000010   \n",
       "\n",
       "race                     name_last  \n",
       "name_last                           \n",
       " Fleurime Michel   Fleurime Michel  \n",
       " Franklin                 Franklin  \n",
       " Grant Cliatt         Grant Cliatt  \n",
       " Hassan                     Hassan  \n",
       " King                         King  \n",
       "...                            ...  \n",
       "Zyzanski                  Zyzanski  \n",
       "Zyzdryn                    Zyzdryn  \n",
       "Zyznomyrsky            Zyznomyrsky  \n",
       "Zzaman                      Zzaman  \n",
       "Zzie                          Zzie  \n",
       "\n",
       "[849826 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf #= gdf[races] / gdf['total_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e0cd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asian', 'hispanic', 'nh_black', 'nh_white', 'total_norm', 'name_last'], dtype='object', name='race')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.drop('total_n', axis=1, inplace=True)\n",
    "gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa752d9",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4a0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer                                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "NGRAMS = 2\n",
    "feature_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2280b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84983, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_df = gdf.sample(frac=0.1, random_state=10)\n",
    "proto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b00e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "\n",
    "# **********\n",
    "# **** CHANGE THIS TO FULL DATAFRAME WHEN READY FOR FULL DATASET ****\n",
    "a = vect.fit_transform(proto_df.name_last)  \n",
    "# **********\n",
    "\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44cd190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 1096\n"
     ]
    }
   ],
   "source": [
    "# n-gram with freq without sorting \n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((a[:, c].sum(), b))\n",
    "\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3706dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54bb95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build X from index of n-gram sequence\n",
    "X = np.array(proto_df.name_last.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "y = np.array(proto_df.iloc[:,:-1])\n",
    "\n",
    "# Generating an equal length sequence of Xs\n",
    "X = sequence.pad_sequences(X, maxlen=feature_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539a3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8a626",
   "metadata": {},
   "source": [
    "# TF-IDF Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f70d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "571a352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(vectorizer, tfidf_transformer, name ):\n",
    "    query_tfidf = vectorizer.transform([name])\n",
    "    cosineSimilarities = cosine_similarity(query_tfidf, tfidf_transformer).flatten()\n",
    "    return cosineSimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb398322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = proto_df['name_last'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55658f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = np.zeros((dim,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88488d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dim):\n",
    "    vect_similarity = get_cosine_similarity(vect, X_train_tfidf, proto_df.iloc[i,-1] )\n",
    "    if (np.where(vect_similarity <= 0.6) and np.where(vect_similarity >= 0)):\n",
    "        cos_similarity[i] = vect_similarity\n",
    "    else:\n",
    "        print (i , ' vector had a large cosine distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "755c03f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96736333, 0.        , 0.        , ..., 0.11255414, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.96030389, 0.        , ..., 0.        , 0.        ,\n",
       "        0.10219411],\n",
       "       [0.        , 0.        , 0.97979594, ..., 0.        , 0.08398708,\n",
       "        0.11614398],\n",
       "       [0.        , 0.13815852, 0.09508934, ..., 0.04973842, 0.12278559,\n",
       "        0.06940931],\n",
       "       [0.        , 0.18268301, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b7578",
   "metadata": {},
   "source": [
    "1. create matrix of bi-chars\n",
    "2. we can do the tf-idf transform\n",
    "3. filter\n",
    "4. using python-Levenshtein (or fuzzywuzzy), calculate levenshtein for the filtered set\n",
    "5. filter again to levenshtein < \n",
    "6. if filtered set > k, then we use all the returned set (so really the mo is to always use the entire returned set) and caculate prop_white, asian, etc., etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
